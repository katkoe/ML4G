{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9a3cc9-f2e3-473a-8286-d9377071d310",
   "metadata": {},
   "source": [
    "# Version 2 (sparse matrices...)\n",
    "### I created the last notebook naively and completely missed that the discusses method operates on sparse matrices, so I'm starting again from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c292f-2131-4f8e-a58b-03aff54d508a",
   "metadata": {},
   "source": [
    "# Generating a sparse matrix representation of a graph..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4159d-e344-4900-9c07-e02cd1556604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "508eddc7-743a-4d1e-a43c-aad72c579ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_nodes = 100\n",
    "average_out_degree = 9\n",
    "total_edge_classes = 36\n",
    "embedding_size = 128\n",
    "output_dim = 4\n",
    "\n",
    "\n",
    "\n",
    "# First we generate some arbitrary graph\n",
    "def generate_graph(num_nodes, average_out_degree, total_edge_classes):\n",
    "    num_edges = average_out_degree*num_nodes\n",
    "    indices = torch.randint(0, num_nodes, (2, num_edges))\n",
    "    print(indices.size())\n",
    "    edges = torch.ones(num_edges)\n",
    "    print(edges.size())\n",
    "    A = torch.sparse_coo_tensor(indices, edges, (num_nodes, num_nodes))\n",
    "    return A\n",
    "# A = generate_graph(15,3,5).to_dense()\n",
    "\n",
    "# Now maybe it's useful to ensure it's connected...\n",
    "def generate_connected_graph(num_nodes, average_out_degree, total_edge_classes, embedding_size):\n",
    "    edges_set = set()\n",
    "    num_edges = average_out_degree * num_nodes\n",
    "\n",
    "    def sample_random_edge_class():\n",
    "        return torch.randint(0, total_edge_classes, (1,)).item()\n",
    "    \n",
    "    def generate_random_edge():\n",
    "        u, v = torch.randint(0, num_nodes, (2,)).tolist()\n",
    "        #no self loops\n",
    "        while u == v:\n",
    "            u, v = torch.randint(0, num_nodes, (2,)).tolist()\n",
    "        return (u, v)\n",
    "    \n",
    "    def generate_random_node():\n",
    "        return torch.randint(0, num_nodes, (1,)).item()\n",
    "    \n",
    "    def sample_random_node(A):\n",
    "        connected_nodes = A._indices()[1].tolist() #select from incoming to...\n",
    "        if not connected_nodes:\n",
    "            return generate_random_node()\n",
    "        return connected_nodes[torch.randint(0, len(connected_nodes), (1,)).item()]#torch.nonzero(A)\n",
    "    \n",
    "    initial_edge = generate_random_edge()\n",
    "    edges_set.add(initial_edge)\n",
    "    indices = torch.tensor([[initial_edge[0]], [initial_edge[1]]], dtype=torch.long, device=device)\n",
    "    edges = torch.ones(1, device=device)\n",
    "    A = torch.sparse_coo_tensor(indices, edges, (num_nodes, num_nodes), device=device)\n",
    "    A_list = []\n",
    "    for edge_class in range(total_edge_classes):\n",
    "        for _ in range(num_edges - 1):\n",
    "            u = sample_random_node(A)\n",
    "            v = generate_random_node()\n",
    "            while u == v:\n",
    "                v = generate_random_node()\n",
    "            new_edge = (u, v)#torch.cat([u, v], dim=0).unsqueeze(1)\n",
    "            if new_edge in edges_set:\n",
    "                continue\n",
    "            edges_set.add(new_edge)\n",
    "            edge_tensor = torch.tensor([[u], [v]], dtype=torch.long, device=device)\n",
    "            indices = torch.cat([indices, edge_tensor], dim=1)\n",
    "            edges = torch.ones(indices.size(1), device=device)\n",
    "            A = torch.sparse_coo_tensor(indices, edges, (num_nodes, num_nodes), device=device)\n",
    "            # indices = torch.stack((indices,torch.cat([u,v]).unsqueeze(1)),dim=0)\n",
    "        # print(edges_set)\n",
    "        A_list.append(A)\n",
    "    random_labels = torch.rand((num_nodes, embedding_size), device=device)\n",
    "    return A_list, random_labels \n",
    "\n",
    "A, X = generate_connected_graph(num_nodes,average_out_degree,total_edge_classes, embedding_size)\n",
    "\n",
    "# Now per edge type? or randomly assign edges...? maybe multinomial_sample(1/k)^k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8687621c-5ccc-4eba-b2e1-9006d1bcd136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6704, 0.5895, 0.8493,  ..., 0.2298, 0.1610, 0.7519],\n",
       "        [0.9928, 0.9682, 0.4486,  ..., 0.8425, 0.8177, 0.9624],\n",
       "        [0.1649, 0.8949, 0.3657,  ..., 0.5884, 0.1401, 0.0713],\n",
       "        ...,\n",
       "        [0.4362, 0.5824, 0.0432,  ..., 0.9224, 0.6386, 0.7155],\n",
       "        [0.6440, 0.7035, 0.2164,  ..., 0.4567, 0.7283, 0.8311],\n",
       "        [0.2540, 0.7553, 0.0965,  ..., 0.8924, 0.4883, 0.6456]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1175c831-5866-40bd-8f7c-3ce5e4d1587a",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6300d86c-3c4b-49a5-b447-6f48bce0629d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     normalized_A \u001b[38;5;241m=\u001b[39m D_inv_sqrt \u001b[38;5;241m@\u001b[39m A \u001b[38;5;241m@\u001b[39m D_inv_sqrt\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalized_A\n\u001b[0;32m---> 16\u001b[0m A_prime \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_adjacency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGCNLayer\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_dim, y_dim):\n",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m, in \u001b[0;36mnormalize_adjacency\u001b[0;34m(A, self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_adjacency\u001b[39m(A, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m): \u001b[38;5;66;03m# Self-loop doesn't work with R-GCN\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m     A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(torch\u001b[38;5;241m.\u001b[39meye(size,device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto_sparse(), A)\n\u001b[1;32m      9\u001b[0m     degree \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39msum(A, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dense()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional as f\n",
    "\n",
    "k_hop = 3\n",
    "\n",
    "def normalize_adjacency(A, self=True): # Self-loop doesn't work with R-GCN\n",
    "    size = A.size()[0]\n",
    "    A = torch.add(torch.eye(size,device=device).to_sparse(), A)\n",
    "    degree = torch.sparse.sum(A, dim=1).to_dense()\n",
    "    # print(degree.size())\n",
    "    d_inv_sqrt = degree.pow(-0.5)\n",
    "    D_inv_sqrt = torch.diag(d_inv_sqrt)\n",
    "    A = A.to_dense()\n",
    "    normalized_A = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return normalized_A\n",
    "A_prime = normalize_adjacency(A)\n",
    "\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        # self.A_norm = A_norm\n",
    "\n",
    "        self.lin = nn.Linear(x_dim, y_dim)\n",
    "\n",
    "    def forward(self, A_norm, X):\n",
    "        device = next(self.parameters()).device\n",
    "        # print(A_norm, X)\n",
    "        transformed = self.lin(X)\n",
    "        aggregated = torch.matmul(A_norm, transformed)\n",
    "        return aggregated\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim, y_dim, max_k_hop):\n",
    "        super(GCN, self).__init__()\n",
    "        self.max_k_hop =max_k_hop\n",
    "        self.x_dim = x_dim\n",
    "        self.gcns = nn.ModuleList([GCNLayer(x_dim, h_dim) for _ in range(max_k_hop)])\n",
    "        self.final_gcn = GCNLayer(x_dim, y_dim) \n",
    "        self.act = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        # self.norm = nn.LayerNorm(y_dim)\n",
    "    \n",
    "    def forward(self, A, X):\n",
    "        # outer layers\n",
    "        device = next(self.parameters()).device\n",
    "        for i in range(self.max_k_hop):\n",
    "            H = self.gcns[i](A, X)\n",
    "            H = self.act(H)\n",
    "            H = self.drop(H)\n",
    "        Y = self.final_gcn(A, H)\n",
    "        out = self.act(Y)\n",
    "        return out#nn.LogSoftmax(Y)\n",
    "model = GCN(X.size(1), embedding_size, output_dim, k_hop).to(device)\n",
    "out = model(A_prime, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870f0f8-f8b3-4003-ac61-f7d6c47a1e46",
   "metadata": {},
   "source": [
    "# R-GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b77995-b03b-409e-ade0-c2e40cbc34a9",
   "metadata": {},
   "source": [
    "### Block diagonal weight matrix (one is held in memory for each relational weight per layer, so block diagonal sparse matrices save some memory at the cost of some layer-level information flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e4257-f40f-44c9-8322-22e4cf8fc3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = embedding_size//4 #some partition... ensure it's a round number\n",
    "relation_weights = [torch.randn(block_size, block_size), torch.randn(block_size, block_size)]\n",
    "\n",
    "block_diag_matrix = torch.block_diag(*relation_weights).to_sparse()\n",
    "block_diag_matrix.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f10d2a2a-7cb7-4133-9c54-dc0d6022b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print( embedding_size//4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c8b48-1db0-4837-95f6-cb2978bc6949",
   "metadata": {},
   "source": [
    "# R-GCN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "603b2e37-fd0f-4e3d-88a5-ec99fe15d455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2029,  0.4855,  0.0000,  0.4661],\n",
       "        [-0.2029,  0.5779,  0.0000,  0.8182],\n",
       "        [-0.2029, -1.4555,  0.0000,  0.7315],\n",
       "        [-0.2029,  0.3165,  0.0000,  0.4782],\n",
       "        [-0.2029, -0.2421,  0.0000,  0.1120],\n",
       "        [-0.2029,  0.5388,  0.0000, -0.4432],\n",
       "        [-0.2029, -1.8544,  0.0000, -1.3735],\n",
       "        [-0.2029,  1.0408,  0.0000,  0.8749],\n",
       "        [-0.2029, -2.0593,  0.0000, -0.5386],\n",
       "        [-0.2029,  1.2324,  0.0000, -0.8722],\n",
       "        [-0.2029, -1.1084,  0.0000,  0.4878],\n",
       "        [-0.2029,  0.3290,  0.0000,  1.5753],\n",
       "        [-0.2029, -0.4637,  0.0000, -0.2371],\n",
       "        [-0.2029, -0.5747,  0.0000,  0.3715],\n",
       "        [-0.2029, -0.9568,  0.0000, -0.2955],\n",
       "        [-0.2029,  1.8275,  0.0000, -0.7516],\n",
       "        [-0.2029,  1.2218,  0.0000,  0.3498],\n",
       "        [-0.2029, -0.2814,  0.0000,  1.6360],\n",
       "        [-0.2029, -0.4658,  0.0000,  0.3716],\n",
       "        [-0.2029, -0.3599,  0.0000, -0.1129],\n",
       "        [ 7.3236,  0.2993,  0.0000, -1.1330],\n",
       "        [ 0.7067, -1.5002,  0.0000,  0.4023],\n",
       "        [-0.2029, -0.5640,  0.0000, -1.2783],\n",
       "        [-0.2029,  0.6464,  0.0000, -0.6069],\n",
       "        [-0.2029,  0.2300,  0.0000, -0.8555],\n",
       "        [-0.2029,  2.5983,  0.0000, -2.7064],\n",
       "        [-0.2029,  0.9777,  0.0000,  0.0560],\n",
       "        [-0.2029, -1.4865,  0.0000,  1.5582],\n",
       "        [-0.2029, -0.2022,  0.0000, -0.2875],\n",
       "        [-0.2029,  0.5921,  0.0000, -0.3652],\n",
       "        [-0.2029,  1.2162,  0.0000, -1.7037],\n",
       "        [-0.2029,  0.3855,  0.0000, -1.0511],\n",
       "        [-0.2029, -1.3000,  0.0000,  0.7027],\n",
       "        [-0.2029, -1.1876,  0.0000,  0.6272],\n",
       "        [-0.2029,  0.1178,  0.0000, -1.2553],\n",
       "        [-0.2029, -1.0278,  0.0000,  2.0243],\n",
       "        [-0.2029, -1.0949,  0.0000,  1.5455],\n",
       "        [-0.2029, -0.3366,  0.0000,  0.5962],\n",
       "        [-0.2029,  0.7668,  0.0000, -1.6094],\n",
       "        [-0.2029, -1.5080,  0.0000,  0.3211],\n",
       "        [-0.2029,  0.5154,  0.0000,  0.4865],\n",
       "        [-0.2029, -0.6442,  0.0000, -1.0284],\n",
       "        [ 1.7573,  0.0873,  0.0000,  1.4577],\n",
       "        [ 5.4071, -0.3592,  0.0000,  0.3177],\n",
       "        [-0.2029, -0.6826,  0.0000,  0.7960],\n",
       "        [-0.2029, -0.3219,  0.0000,  0.0294],\n",
       "        [ 0.8968, -0.0791,  0.0000, -0.3877],\n",
       "        [-0.2029, -1.1534,  0.0000,  0.6429],\n",
       "        [-0.2029,  0.8245,  0.0000, -1.6899],\n",
       "        [-0.2029,  1.3080,  0.0000, -0.4282],\n",
       "        [-0.2029,  0.6233,  0.0000,  0.0255],\n",
       "        [-0.2029, -1.0885,  0.0000, -0.2864],\n",
       "        [-0.2029, -0.6379,  0.0000, -0.6554],\n",
       "        [-0.2029, -0.6769,  0.0000,  0.0947],\n",
       "        [-0.2029,  0.1041,  0.0000, -0.9968],\n",
       "        [-0.2029,  0.8242,  0.0000,  0.0782],\n",
       "        [-0.2029,  0.3565,  0.0000, -0.9664],\n",
       "        [-0.2029, -1.6530,  0.0000,  0.7767],\n",
       "        [-0.2029,  0.1694,  0.0000,  1.2607],\n",
       "        [-0.2029,  0.8183,  0.0000, -0.1825],\n",
       "        [-0.2029, -1.7321,  0.0000,  0.5567],\n",
       "        [-0.2029, -0.6062,  0.0000,  1.6649],\n",
       "        [-0.2029,  0.2292,  0.0000, -0.3635],\n",
       "        [-0.2029,  1.3312,  0.0000,  0.4471],\n",
       "        [-0.2029, -0.6071,  0.0000, -0.4293],\n",
       "        [-0.2029,  0.7956,  0.0000, -1.6853],\n",
       "        [-0.2029,  0.0574,  0.0000,  0.2151],\n",
       "        [-0.2029, -0.4133,  0.0000,  1.7134],\n",
       "        [-0.2029, -1.0116,  0.0000,  1.8385],\n",
       "        [-0.2029,  1.8688,  0.0000,  0.1542],\n",
       "        [-0.2029,  0.3838,  0.0000, -0.3746],\n",
       "        [-0.2029,  0.0673,  0.0000, -0.1755],\n",
       "        [-0.2029,  0.5884,  0.0000, -0.0278],\n",
       "        [-0.2029,  1.5808,  0.0000, -1.1084],\n",
       "        [-0.2029, -0.2103,  0.0000, -2.4071],\n",
       "        [-0.2029,  2.7588,  0.0000, -0.2177],\n",
       "        [-0.2029, -1.3713,  0.0000,  0.6386],\n",
       "        [-0.2029, -0.8842,  0.0000,  1.2910],\n",
       "        [-0.2029, -1.8042,  0.0000,  1.7491],\n",
       "        [-0.2029,  0.3051,  0.0000, -1.7306],\n",
       "        [-0.2029, -0.9750,  0.0000,  1.5803],\n",
       "        [-0.2029, -0.3468,  0.0000, -0.0767],\n",
       "        [-0.2029,  1.1037,  0.0000,  0.2048],\n",
       "        [-0.2029, -0.3788,  0.0000,  0.3699],\n",
       "        [-0.2029,  1.0587,  0.0000, -0.9834],\n",
       "        [-0.2029, -0.6712,  0.0000, -0.1503],\n",
       "        [-0.2029, -0.3658,  0.0000, -0.0377],\n",
       "        [-0.2029,  2.2741,  0.0000, -0.5012],\n",
       "        [-0.2029,  1.1482,  0.0000, -0.6426],\n",
       "        [-0.2029, -0.5439,  0.0000,  0.6846],\n",
       "        [-0.2029,  0.7796,  0.0000,  1.4366],\n",
       "        [-0.2029,  0.7954,  0.0000, -0.5288],\n",
       "        [ 2.9767,  0.2152,  0.0000,  0.3149],\n",
       "        [-0.2029,  1.4176,  0.0000, -2.5998],\n",
       "        [-0.2029, -0.3162,  0.0000,  0.3836],\n",
       "        [-0.2029, -0.4779,  0.0000,  0.0673],\n",
       "        [-0.2029,  0.2125,  0.0000, -1.2521],\n",
       "        [-0.2029, -0.7735,  0.0000,  0.6728],\n",
       "        [-0.2029,  0.0553,  0.0000,  0.4941],\n",
       "        [-0.2029,  0.7579,  0.0000,  0.8411]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_adjacency(A, self=True): # Self-loop doesn't work with R-GCN\n",
    "    size = A.size()[0]\n",
    "    A = torch.add(torch.eye(size,device=device).to_sparse(), A)\n",
    "    degree = torch.sparse.sum(A, dim=1).to_dense()\n",
    "    # print(degree.size())\n",
    "    d_inv_sqrt = degree.pow(-0.5)\n",
    "    D_inv_sqrt = torch.diag(d_inv_sqrt)\n",
    "    A = A.to_dense()\n",
    "    normalized_A = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return normalized_A\n",
    "# A_prime = normalize_adjacency(A)\n",
    "\n",
    "A_list = [normalize_adjacency(a, False) for a in A]\n",
    "\n",
    "\n",
    "##save non-error version\n",
    "def block_diag (weights):\n",
    "    block_diag_matrix = torch.block_diag(*weights).to_sparse()\n",
    "    return block_diag_matrix\n",
    "    \n",
    "\n",
    "class R_GCNLayer(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim, num_relations, block_split):\n",
    "        super(R_GCNLayer, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.num_relations = num_relations\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        max_block_size = 1\n",
    "        for i in range(1,11):\n",
    "            if x_dim % i == 0 and y_dim % i == 0:\n",
    "                max_block_size +=1 \n",
    "        x_block_size = x_dim // block_split\n",
    "        y_block_size = y_dim // block_split\n",
    "        self.W = nn.ParameterList()\n",
    "        for _ in range(num_relations):\n",
    "            wr = nn.ParameterList()\n",
    "            # relation_weights = []\n",
    "            for i in range(block_split):\n",
    "                w = nn.Parameter(torch.randn(x_block_size, y_block_size)) \n",
    "                nn.init.kaiming_uniform_(w, a=gain)\n",
    "                # relation_weights.append(w)\n",
    "             #move blocks to params, not block diag\n",
    "            # print(block_diag_matrix)\n",
    "                wr.append(w)\n",
    "                # self.Wr.append(wr)\n",
    "            self.W.append(wr)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.zeros(y_dim))\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "#dense version change forward loop such that weigted is matmul, etc of blockdiag(w)\n",
    "# def block_diag (weights):\n",
    "#     block_diag_matrix = torch.block_diag(*weights)\n",
    "#     return block_diag_matrix\n",
    "    \n",
    "\n",
    "# class R_GCNLayer(nn.Module):\n",
    "#     def __init__(self, x_dim, y_dim, num_relations, block_split):\n",
    "#         super(R_GCNLayer, self).__init__()\n",
    "#         self.x_dim = x_dim\n",
    "#         self.y_dim = y_dim\n",
    "#         self.num_relations = num_relations\n",
    "#         gain = nn.init.calculate_gain('relu')\n",
    "#         max_block_size = 1\n",
    "#         for i in range(1,11):\n",
    "#             if x_dim % i == 0 and y_dim % i == 0:\n",
    "#                 max_block_size +=1 \n",
    "#         x_block_size = x_dim // block_split\n",
    "#         y_block_size = y_dim // block_split\n",
    "#         self.W = nn.ParameterList()\n",
    "#         for _ in range(num_relations):\n",
    "#             # wr = nn.ParameterList()\n",
    "#             relation_weights = []\n",
    "#             for i in range(block_split):\n",
    "#                 w = torch.randn(x_block_size, y_block_size)\n",
    "#                 relation_weights.append(w)\n",
    "#                 nn.init.kaiming_uniform_(block_diag_dense, a=gain)\n",
    "#             block_diag_dense = block_diag(relation_weights)\n",
    "#             # print(block_diag_dense)\n",
    "#              #move blocks to params, not block diag\n",
    "#             # print(block_diag_matrix)\n",
    "#                 # wr.append(w)\n",
    "#             self.W.append(block_diag_dense)\n",
    "#             # self.W.append(wr)\n",
    "\n",
    "#         self.bias = nn.Parameter(torch.zeros(y_dim))\n",
    "#         nn.init.zeros_(self.bias)\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, A, X):\n",
    "        device = next(self.parameters()).device\n",
    "        aggregated = torch.zeros((X.size(0), self.y_dim), device=device)\n",
    "        # print(self.W[1], self.W[1].size())\n",
    "        for r in range(self.num_relations):\n",
    "            # print(block_diag(self.W[r]).to_dense())\n",
    "            # print(X.size(), self.Wr[r])\n",
    "            weighted = torch.matmul(X, block_diag(self.W[r]))  # (num_nodes, out_dim)\n",
    "            # print(weighted.size())\n",
    "            transformed = torch.sparse.mm(A[r], weighted)\n",
    "            # aggregated_r = torch.matmul(A_norm, transformed)\n",
    "            # print(aggregated.size(), transformed.size())\n",
    "            aggregated += transformed\n",
    "        aggregated += self.bias\n",
    "        return aggregated\n",
    "\n",
    "\n",
    "class R_GCN(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim, y_dim, max_k_hop, num_relations):\n",
    "        super(R_GCN, self).__init__()\n",
    "        self.max_k_hop =max_k_hop\n",
    "        self.num_relations = num_relations\n",
    "        self.x_dim = x_dim\n",
    "        self.block_split = 2\n",
    "        self.gcns = nn.ModuleList([R_GCNLayer(x_dim, h_dim, num_relations, self.block_split) for _ in range(max_k_hop)])\n",
    "        self.final_r_gcn = R_GCNLayer(x_dim, y_dim,num_relations, self.block_split) \n",
    "        self.act = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        # self.norm = nn.LayerNorm(y_dim)\n",
    "        self.norm = nn.BatchNorm1d(y_dim)\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    def forward(self, A, X):\n",
    "        # outer layers\n",
    "        device = next(self.parameters()).device\n",
    "        for i in range(self.max_k_hop):\n",
    "            H = self.gcns[i](A, X)\n",
    "            H = self.act(H)\n",
    "            H = self.drop(H)\n",
    "        Y = self.final_r_gcn(A, H)\n",
    "        out = self.act(Y)\n",
    "        out = self.norm(out)\n",
    "        return out#nn.LogSoftmax(Y)\n",
    "model = R_GCN(X.size(1), embedding_size, output_dim, k_hop, total_edge_classes).to(device)\n",
    "out = model(A_list, X)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "738743cd-c50b-4103-8130-e28d8746ae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7295ba-260f-4eb1-86c4-6c1c2dd67825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f738fa3-694a-46dc-bdf6-9438be741943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc738f59-b939-4037-8859-d4e70f0b9150",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea2c0aef-fcd4-4f35-bb0a-23bb5d85e2a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                          | 2/600 [00:00<02:14,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "avg loss: 1.524507999420166 accuracy: 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                          | 7/600 [00:01<01:32,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "avg loss: 1.4015671014785767 accuracy: 34.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                         | 12/600 [00:02<02:22,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\n",
      "avg loss: 1.3542121648788452 accuracy: 43.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                        | 17/600 [00:03<01:31,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15\n",
      "avg loss: 1.3514102697372437 accuracy: 33.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                        | 21/600 [00:04<02:40,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20\n",
      "avg loss: 1.3495310544967651 accuracy: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▉                                        | 27/600 [00:05<01:43,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25\n",
      "avg loss: 1.3472623825073242 accuracy: 41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                       | 32/600 [00:06<01:25,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30\n",
      "avg loss: 1.3439117670059204 accuracy: 35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                       | 37/600 [00:07<01:21,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35\n",
      "avg loss: 1.309199333190918 accuracy: 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                       | 42/600 [00:07<01:22,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40\n",
      "avg loss: 1.3285068273544312 accuracy: 34.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                      | 47/600 [00:08<01:19,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45\n",
      "avg loss: 1.2921274900436401 accuracy: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▋                                      | 52/600 [00:09<01:18,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50\n",
      "avg loss: 1.3122432231903076 accuracy: 39.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▉                                      | 57/600 [00:10<01:21,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55\n",
      "avg loss: 1.2917721271514893 accuracy: 41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                     | 62/600 [00:10<01:17,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60\n",
      "avg loss: 1.3459113836288452 accuracy: 37.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▋                                     | 67/600 [00:11<01:16,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65\n",
      "avg loss: 1.2794016599655151 accuracy: 47.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████                                     | 72/600 [00:12<01:15,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70\n",
      "avg loss: 1.2659642696380615 accuracy: 41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▍                                    | 77/600 [00:13<01:14,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75\n",
      "avg loss: 1.281798243522644 accuracy: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▋                                    | 82/600 [00:13<01:13,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 80\n",
      "avg loss: 1.2759076356887817 accuracy: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████                                    | 86/600 [00:15<02:26,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85\n",
      "avg loss: 1.279822826385498 accuracy: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████▍                                   | 92/600 [00:16<01:25,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 90\n",
      "avg loss: 1.2701709270477295 accuracy: 41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▋                                   | 96/600 [00:17<02:03,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95\n",
      "avg loss: 1.2736297845840454 accuracy: 43.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▉                                  | 101/600 [00:18<02:36,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100\n",
      "avg loss: 1.2548794746398926 accuracy: 44.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▏                                 | 106/600 [00:20<02:38,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 105\n",
      "avg loss: 1.2558616399765015 accuracy: 41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▌                                 | 111/600 [00:21<02:38,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 110\n",
      "avg loss: 1.2488245964050293 accuracy: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▉                                 | 116/600 [00:23<02:19,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 115\n",
      "avg loss: 1.2044368982315063 accuracy: 42.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▎                                | 122/600 [00:24<01:20,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 120\n",
      "avg loss: 1.1971265077590942 accuracy: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▋                                | 127/600 [00:25<01:09,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 125\n",
      "avg loss: 1.23415207862854 accuracy: 46.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▉                                | 131/600 [00:25<01:33,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 130\n",
      "avg loss: 1.1870958805084229 accuracy: 41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▎                               | 137/600 [00:27<01:46,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 135\n",
      "avg loss: 1.1799806356430054 accuracy: 46.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▋                               | 141/600 [00:28<01:15,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 140\n",
      "avg loss: 1.1739649772644043 accuracy: 49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████                               | 147/600 [00:29<01:24,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 145\n",
      "avg loss: 1.1880673170089722 accuracy: 45.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▍                              | 152/600 [00:30<01:06,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 150\n",
      "avg loss: 1.1831810474395752 accuracy: 53.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████▋                              | 157/600 [00:31<01:29,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 155\n",
      "avg loss: 1.1270793676376343 accuracy: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████                              | 162/600 [00:32<01:05,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 160\n",
      "avg loss: 1.1462008953094482 accuracy: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████▎                             | 166/600 [00:32<01:02,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 165\n",
      "avg loss: 1.1707470417022705 accuracy: 45.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████▋                             | 171/600 [00:34<02:11,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 170\n",
      "avg loss: 1.077985405921936 accuracy: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████                             | 177/600 [00:36<01:36,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 175\n",
      "avg loss: 1.1419662237167358 accuracy: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▍                            | 182/600 [00:36<01:04,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 180\n",
      "avg loss: 1.144460678100586 accuracy: 51.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████▊                            | 187/600 [00:37<00:58,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 185\n",
      "avg loss: 1.1688612699508667 accuracy: 44.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████                            | 192/600 [00:38<00:56,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 190\n",
      "avg loss: 1.103809118270874 accuracy: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▍                           | 196/600 [00:38<01:23,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 195\n",
      "avg loss: 1.115091323852539 accuracy: 49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████▊                           | 202/600 [00:40<01:14,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200\n",
      "avg loss: 1.0746572017669678 accuracy: 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████▏                          | 207/600 [00:41<00:58,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 205\n",
      "avg loss: 1.1027384996414185 accuracy: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████▍                          | 212/600 [00:41<00:54,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 210\n",
      "avg loss: 1.0325841903686523 accuracy: 59.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▊                          | 217/600 [00:42<00:53,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 215\n",
      "avg loss: 1.093115210533142 accuracy: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████                          | 221/600 [00:43<00:52,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 220\n",
      "avg loss: 1.1790440082550049 accuracy: 43.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████▍                         | 226/600 [00:44<01:51,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 225\n",
      "avg loss: 1.1730895042419434 accuracy: 49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████▊                         | 232/600 [00:46<01:39,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 230\n",
      "avg loss: 1.1265952587127686 accuracy: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▏                        | 237/600 [00:47<00:59,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 235\n",
      "avg loss: 1.1131348609924316 accuracy: 53.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▌                        | 242/600 [00:47<00:51,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 240\n",
      "avg loss: 1.1782243251800537 accuracy: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████▊                        | 246/600 [00:48<01:10,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 245\n",
      "avg loss: 1.0937623977661133 accuracy: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████▏                       | 251/600 [00:50<01:47,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 250\n",
      "avg loss: 1.0877245664596558 accuracy: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▍                       | 256/600 [00:51<01:50,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 255\n",
      "avg loss: 1.164635419845581 accuracy: 51.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████▊                       | 261/600 [00:53<01:50,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 260\n",
      "avg loss: 1.092973232269287 accuracy: 53.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████▏                      | 266/600 [00:55<01:48,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 265\n",
      "avg loss: 1.1347428560256958 accuracy: 51.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████▌                      | 271/600 [00:56<01:43,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 270\n",
      "avg loss: 1.0954760313034058 accuracy: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████▊                      | 276/600 [00:57<01:09,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 275\n",
      "avg loss: 1.051997423171997 accuracy: 54.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████▎                     | 282/600 [00:58<00:55,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 280\n",
      "avg loss: 1.054595708847046 accuracy: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████▌                     | 287/600 [00:59<00:45,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 285\n",
      "avg loss: 1.0293818712234497 accuracy: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████▉                     | 292/600 [01:00<00:43,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 290\n",
      "avg loss: 1.010118842124939 accuracy: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████▎                    | 297/600 [01:01<00:42,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 295\n",
      "avg loss: 1.054264783859253 accuracy: 54.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████▌                    | 301/600 [01:01<00:41,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 300\n",
      "avg loss: 1.005678653717041 accuracy: 58.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████▉                    | 307/600 [01:02<00:53,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 305\n",
      "avg loss: 1.0025187730789185 accuracy: 61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████▎                   | 312/600 [01:03<00:42,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 310\n",
      "avg loss: 1.0324794054031372 accuracy: 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▋                   | 317/600 [01:04<00:39,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 315\n",
      "avg loss: 1.027179479598999 accuracy: 51.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████                   | 322/600 [01:05<00:40,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 320\n",
      "avg loss: 0.9974989295005798 accuracy: 61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████▎                  | 327/600 [01:05<00:38,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 325\n",
      "avg loss: 0.9491453766822815 accuracy: 58.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████▋                  | 332/600 [01:06<00:43,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 330\n",
      "avg loss: 1.0478346347808838 accuracy: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████▉                  | 336/600 [01:07<00:53,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 335\n",
      "avg loss: 0.9456179141998291 accuracy: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████▎                 | 342/600 [01:08<00:57,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 340\n",
      "avg loss: 0.8786041736602783 accuracy: 67.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████▋                 | 347/600 [01:10<00:54,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 345\n",
      "avg loss: 0.9452252984046936 accuracy: 63.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████▉                 | 351/600 [01:11<01:15,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 350\n",
      "avg loss: 0.8861430287361145 accuracy: 65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████▎                | 356/600 [01:13<01:18,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 355\n",
      "avg loss: 0.9281129240989685 accuracy: 60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████▋                | 361/600 [01:14<01:17,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 360\n",
      "avg loss: 0.8788821697235107 accuracy: 61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████                | 366/600 [01:16<01:09,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 365\n",
      "avg loss: 0.8767220973968506 accuracy: 65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████▎               | 371/600 [01:17<01:13,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 370\n",
      "avg loss: 0.8571144938468933 accuracy: 63.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████▋               | 376/600 [01:19<01:12,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 375\n",
      "avg loss: 0.8612250685691833 accuracy: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████               | 382/600 [01:21<00:59,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 380\n",
      "avg loss: 0.9050018787384033 accuracy: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████▍              | 387/600 [01:21<00:34,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 385\n",
      "avg loss: 0.8824501633644104 accuracy: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████▊              | 392/600 [01:22<00:29,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 390\n",
      "avg loss: 0.8231688141822815 accuracy: 60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████              | 396/600 [01:23<00:51,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 395\n",
      "avg loss: 0.9229439496994019 accuracy: 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████▍             | 401/600 [01:25<01:01,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 400\n",
      "avg loss: 0.8714409470558167 accuracy: 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████▋             | 406/600 [01:26<01:04,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 405\n",
      "avg loss: 0.8388002514839172 accuracy: 67.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████             | 411/600 [01:28<01:01,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 410\n",
      "avg loss: 0.858518660068512 accuracy: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████▍            | 416/600 [01:30<00:59,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 415\n",
      "avg loss: 0.8606392741203308 accuracy: 65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████▊            | 422/600 [01:32<00:49,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 420\n",
      "avg loss: 0.9074292182922363 accuracy: 66.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████▏           | 427/600 [01:32<00:28,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 425\n",
      "avg loss: 0.7904000878334045 accuracy: 65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████▌           | 432/600 [01:33<00:24,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 430\n",
      "avg loss: 0.9044851660728455 accuracy: 65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████▊           | 437/600 [01:34<00:23,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 435\n",
      "avg loss: 0.8339964151382446 accuracy: 66.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████▏          | 442/600 [01:34<00:22,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 440\n",
      "avg loss: 0.7939798831939697 accuracy: 63.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████▍          | 446/600 [01:35<00:21,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 445\n",
      "avg loss: 0.8780575394630432 accuracy: 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████▊          | 451/600 [01:37<00:44,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 450\n",
      "avg loss: 0.9870428442955017 accuracy: 54.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████▏         | 456/600 [01:38<00:46,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 455\n",
      "avg loss: 0.9165701270103455 accuracy: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████▌         | 461/600 [01:40<00:44,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 460\n",
      "avg loss: 0.8253042697906494 accuracy: 59.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████▊         | 466/600 [01:41<00:42,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 465\n",
      "avg loss: 0.8652363419532776 accuracy: 58.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████▏        | 471/600 [01:43<00:41,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 470\n",
      "avg loss: 0.8790467977523804 accuracy: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████▌        | 477/600 [01:44<00:21,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 475\n",
      "avg loss: 0.906903088092804 accuracy: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████▊        | 481/600 [01:45<00:28,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 480\n",
      "avg loss: 0.8562385439872742 accuracy: 61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████▏       | 486/600 [01:47<00:34,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 485\n",
      "avg loss: 0.8423547148704529 accuracy: 59.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████▌       | 491/600 [01:48<00:35,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 490\n",
      "avg loss: 0.8060154914855957 accuracy: 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████▉       | 496/600 [01:50<00:33,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 495\n",
      "avg loss: 0.8087769150733948 accuracy: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████▏      | 501/600 [01:51<00:32,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 500\n",
      "avg loss: 0.8371729850769043 accuracy: 60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████▌      | 506/600 [01:53<00:30,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 505\n",
      "avg loss: 0.8683082461357117 accuracy: 60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████▉      | 512/600 [01:54<00:19,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 510\n",
      "avg loss: 0.8993200659751892 accuracy: 58.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████▎     | 517/600 [01:55<00:12,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 515\n",
      "avg loss: 0.9263912439346313 accuracy: 60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████▋     | 522/600 [01:56<00:10,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 520\n",
      "avg loss: 0.8035109043121338 accuracy: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████     | 527/600 [01:57<00:10,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 525\n",
      "avg loss: 0.7605675458908081 accuracy: 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████▎    | 532/600 [01:57<00:09,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 530\n",
      "avg loss: 0.8301758766174316 accuracy: 61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████▋    | 537/600 [01:58<00:09,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 535\n",
      "avg loss: 0.8696222901344299 accuracy: 59.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████    | 542/600 [01:59<00:08,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 540\n",
      "avg loss: 0.8617804050445557 accuracy: 57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████▍   | 547/600 [01:59<00:07,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 545\n",
      "avg loss: 0.8542235493659973 accuracy: 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████▋   | 552/600 [02:00<00:06,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 550\n",
      "avg loss: 0.8299148678779602 accuracy: 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████   | 557/600 [02:01<00:05,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 555\n",
      "avg loss: 0.8399718999862671 accuracy: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████▍  | 562/600 [02:02<00:05,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 560\n",
      "avg loss: 0.763938844203949 accuracy: 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████▋  | 567/600 [02:02<00:04,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 565\n",
      "avg loss: 0.7647873759269714 accuracy: 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████  | 571/600 [02:03<00:04,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 570\n",
      "avg loss: 0.7708765268325806 accuracy: 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████▍ | 577/600 [02:04<00:03,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 575\n",
      "avg loss: 0.7578765153884888 accuracy: 65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████▊ | 582/600 [02:04<00:02,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 580\n",
      "avg loss: 0.7962588667869568 accuracy: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████ | 587/600 [02:05<00:01,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 585\n",
      "avg loss: 0.7253901958465576 accuracy: 67.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████▍| 592/600 [02:06<00:01,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 590\n",
      "avg loss: 0.7674355506896973 accuracy: 61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████▋| 596/600 [02:07<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 595\n",
      "avg loss: 0.8034726977348328 accuracy: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 600/600 [02:07<00:00,  4.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "from tqdm import tqdm\n",
    "criterion = nn.CrossEntropyLoss()#nn.NLLLoss()\n",
    "params = list(model.parameters())\n",
    "# params.extend(list(classifier.parameters()))\n",
    "optimizer = torch.optim.Adam(params,lr=0.01)\n",
    "\n",
    "num_epochs = 600\n",
    "\n",
    "true_labels = torch.randint(0, output_dim, (num_nodes,), dtype=torch.long).to(device)\n",
    "\n",
    "# print(true_labels)\n",
    "\n",
    "def save_gradient_hook(grad):\n",
    "    gradients.append(grad)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):#, desc = f\"epoch {epoch}/{num_epochs}\"):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    i = 0\n",
    "\n",
    "    predicted_labels = model(A_list, X)\n",
    "    \n",
    "    loss = criterion(predicted_labels, true_labels)\n",
    "\n",
    "    # for param in params:\n",
    "    #     param.register_hook(save_gradient_hook)\n",
    "    \n",
    "    # if i % batch_size == 0:\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    i += 1\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    _, predicted = torch.max(predicted_labels.data, 1)\n",
    "    total += true_labels.size(0)\n",
    "    correct += (predicted == true_labels).sum().item()\n",
    "    avg_loss = epoch_loss\n",
    "    accuracy = 100 * correct / total\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"epoch: {epoch}\\navg loss: {avg_loss} accuracy: {accuracy}\")\n",
    "        # make_dot(predicted_labels, params=dict(list(model.named_parameters()))).render(\"r_gcn_torchviz\", format=\"png\")\n",
    "\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8288b8-687d-4645-b942-75ab8bebe744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c268095-1f9a-401d-aa33-b27ec4da3408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92ff5184-21dd-40ee-ad5d-10a0e7632c6c",
   "metadata": {},
   "source": [
    "# I'm confused about the rdf stuff. I don't see any multimodal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a6513d3-0373-42a9-b114-907ea0e5fabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 0, 3, 2, 3, 2, 0, 1, 1, 2, 3, 1, 1, 2, 0, 1, 1, 3, 0, 2, 2, 1, 3,\n",
       "        1, 1, 3, 2, 0, 3, 1, 1, 3, 0, 2, 2, 0, 2, 2, 1, 2, 2, 3, 1, 3, 1, 3, 2,\n",
       "        1, 2, 1, 2, 2, 3, 2, 1, 0, 1, 3, 0, 1, 3, 1, 2, 3, 0, 2, 2, 0, 1, 1, 0,\n",
       "        3, 2, 1, 2, 0, 0, 0, 1, 2, 0, 0, 2, 3, 1, 1, 2, 3, 1, 3, 3, 3, 3, 3, 0,\n",
       "        0, 1, 1, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "365d0e07-a704-4346-b9b4-92d49d45becd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 0, 3, 0, 3, 1, 0, 1, 1, 1, 3, 1, 3, 1, 0, 1, 3, 3, 1, 1, 1, 1, 3,\n",
       "        1, 1, 3, 1, 0, 3, 3, 1, 3, 1, 1, 1, 0, 0, 1, 1, 1, 1, 3, 1, 1, 1, 3, 3,\n",
       "        1, 1, 0, 1, 1, 3, 1, 1, 0, 1, 3, 1, 1, 3, 0, 1, 3, 1, 3, 0, 1, 1, 0, 0,\n",
       "        3, 3, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 3, 1, 0, 0, 3, 0, 3, 3, 1, 3, 3, 0,\n",
       "        0, 1, 1, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef63b0-c9f1-44b7-ae9e-09210b4395c9",
   "metadata": {},
   "source": [
    "# Create graph from n-triple file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b7f1d5-1f5a-44d8-b1f2-764a729e737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib import Graph\n",
    "import logging\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "data_loc = './Downloads/ml4g/dmg/mmkg/dmg/scripts/dmg777k_stripped.nt'\n",
    "folder = './Downloads/ml4g'\n",
    "\n",
    "def create_new_graph(path, batch_size = 1000, test=True):\n",
    "    logging.basicConfig(\n",
    "    filename='rdf_parsing_errors.log',\n",
    "    filemode='w')\n",
    "    \n",
    "    graph = Graph()\n",
    "    # graph = graph.parse(, format='nt')\n",
    "    batch_num = 0\n",
    "    i = 0\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        while True:\n",
    "            batch = []\n",
    "            try:\n",
    "                [batch.append(next(f)) for j in range(batch_size)]\n",
    "                i += j\n",
    "            except:\n",
    "                pass\n",
    "            if not batch:\n",
    "                break\n",
    "            batch_num += 1\n",
    "            nt_string = ''.join(batch)\n",
    "            try:\n",
    "                graph.parse(data=nt_string, format='nt')\n",
    "                if test:\n",
    "                    graph = Graph()\n",
    "            except ParseError as e:\n",
    "                logging.error(f\"in batch: {batch_num}:\\npproblematic data:\\n\\n{batch}\\n\\n\")\n",
    "                check(batch, batch_num, test=test)\n",
    "\n",
    "            if batch_num == 5:\n",
    "                # print(batch)\n",
    "                pass\n",
    "            if batch_num % 10 == 0:\n",
    "                # clear_output()\n",
    "                \n",
    "                pass\n",
    "                # print(f\"{batch_num}/:o?\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "def check(batch, batch_num, test = True):\n",
    "    graph = Graph()\n",
    "    for i, line in enumerate(batch):\n",
    "        try:\n",
    "            graph.parse(line)\n",
    "        except Exception as e:\n",
    "            logging.error(f'in line: {i}:\\n{line}\\n{e}')\n",
    "graph=create_new_graph(data_loc, test=False)\n",
    "# graph = Graph()\n",
    "# graph.parse(data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a1a7a1df-aa03-4867-b493-41b5e47c30d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777124"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "node_set = set()\n",
    "edge_set = set()\n",
    "string_set = set()\n",
    "image_set = set()\n",
    "num_set = set()\n",
    "poly_set = set()\n",
    "date_set = set()\n",
    "point_set = set()\n",
    "i = 0\n",
    "\n",
    "def is_date(date_string):\n",
    "    try:\n",
    "        datetime.strptime(date_string, '%Y-%m-%d')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "for s,p,o in graph:\n",
    "    i+=1\n",
    "    pi = p.identifier\n",
    "    for node in [s,o]:\n",
    "        ni = node.identifier\n",
    "        # if 'http' in ni[:200] and 'geonames' not in ni: #just add geonames to node set I think...\n",
    "        if 'http' in ni[:200]: #200, because images sometimes have kgbench url attached\n",
    "            node_set.add(''.join(ni.split(':')[1].split('/')[:-1]))\n",
    "        else:\n",
    "            if node.isalnum():\n",
    "                if node.isnumeric():\n",
    "                    if node.isdigit():\n",
    "                        num_set.add(int(node.identifier))\n",
    "                    else:\n",
    "                        num_set.add(float(node.identifier))\n",
    "            elif ni.startswith('POINT') or ni.startswith('Point'): #didn't see any points, but according to the paper they can be included.\n",
    "                point_set.add(ni)\n",
    "            elif node.isalpha(): #maybe elif maybe not dunno if it filters out strings with numbers\n",
    "                string_set.add(ni)\n",
    "            elif ni.startswith('_9j_'):\n",
    "                image_set.add(ni) #might want to load this to hard drive if memory becomes an issue.\n",
    "            elif ni.startswith('POLYGON') or ni.startswith('Polygon'):\n",
    "                poly_set.add(ni)\n",
    "            elif is_date(ni):\n",
    "                date_set.add(ni)\n",
    "            elif ni.isascii():\n",
    "                string_set.add(ni)\n",
    "            elif ni.isprintable():\n",
    "                string_set.add(ascii(ni)) #don't know if it's necessary, but it probably can't hurt\n",
    "            else: #all that's left seems to be monument stories and property description related text. \n",
    "                            #If there's an error later it's probably from here\n",
    "                string_set.add(ascii(ni))\n",
    "                \n",
    "                # print(ni.isalpha(),ni)\n",
    "                \n",
    "\n",
    "\n",
    "    edge_set.add(p)\n",
    "\n",
    "    \n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8c1f2dbe-df3b-421e-a165-16b8e26b118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import printable\n",
    "\n",
    "character_map = {i:char for i,char in enumerate(printable[:95])} #exclude \\t and such specific characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd4067-852c-4807-bc0b-417be80a827f",
   "metadata": {},
   "source": [
    "# Convert raw values to consistent feature vectors for the encoders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6dae313d-9b47-4d52-9375-7994e6691bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point(5.948392853085229 52.659852423418606)\n",
      "(7.161238424712663, 53.11030897180887)\n",
      "Point(5.948392853085229 52.659852423418606)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from string import printable\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "node_map = {i:node for i,node in enumerate(node_set)}\n",
    "inv_node_map = {node:i for i,node in enumerate(node_set)}\n",
    "\n",
    "edge_map = {i:edge for i,edge in enumerate(edge_set)}\n",
    "inv_edge_map = {edge:i for i,edge in enumerate(edge_set)}\n",
    "\n",
    "def tokenize_string(s, character_map):\n",
    "    #preprocess for text encoder[1](? layer temporal cnn -->embedding_dim)\n",
    "\n",
    "    #character level embeddings\n",
    "    tokens = [character_map[char] for char in s]\n",
    "    return tokens #\n",
    "\n",
    "def encode_image(img_data):\n",
    "    #preprocess for encoder[2](2 layer cnn -->embedding_dim)\n",
    "    return #maybe save tokens & image representation to hard drive?\n",
    "\n",
    "def encode_num(n, max_num):\n",
    "    # read how it's done exactly.. cat(e(num),e(bool))\n",
    "    # maybe add log scale if max_num is really high...\n",
    "    v = n/max_num\n",
    "    return torch.tensor(v,dtype=torch.float32, device=device)\n",
    "\n",
    "def encode_polygon(poly, global_mean_x, global_mean_y, x_max, y_max):\n",
    "    #preprocess for spatial encoder[3](? layer temporal cnn -->embedding_dim) \n",
    "    poly_tensor_x = (global_mean_x-torch.tensor([ point[0] for point in poly], dtype=torch.float32, device=device))/x_max\n",
    "    poly_tensor_y = (global_mean_y-torch.tensor([ point[1] for point in poly], dtype=torch.float32, device=device))/y_max\n",
    "    # print(poly_tensor_x)\n",
    "    return torch.stack((poly_tensor_x,poly_tensor_y),dim=0)\n",
    "\n",
    "def encode_point(point, max_x, max_y):\n",
    "    #preprocess for spatial encoder[3](? layer temporal cnn -->embedding_dim)\n",
    "    \n",
    "    point = torch.tensor(point,dtype=torch.float32, device=device)\n",
    "    div = torch.tensor((max_x,max_y),dtype=torch.float32, device=device)\n",
    "    return point/div\n",
    "\n",
    "def encode_date(date):\n",
    "    #preprocess for temporal encoder[4](? layer ffnn -->embedding_dim)\n",
    "    def cyclical(num, max_num, epsilon = 1e-8):\n",
    "        # cyclical: [sine((2pi * X)/max_num_of_cycle) cos((2pi * X)/max_num_of_cycle)]\n",
    "        return torch.tensor([math.sin((2 * math.pi * num)/max_num)+epsilon, math.cos((2 * math.pi * num)/max_num)+epsilon],dtype=torch.float32, device=device)\n",
    "        \n",
    "    def norm_cent(num):\n",
    "        # non-cyclical only centuries: normalized from -99 to 99 (-9999 bc to 9999 ac)\n",
    "        return torch.tensor((num + 99)/198,dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        \n",
    "    split_str = date.split('-')\n",
    "    years_str = split_str[0]\n",
    "    month_str = split_str[1]\n",
    "    day_str = split_str[2]\n",
    "    centuries = norm_cent(int(years_str[:-2]))\n",
    "    decades = cyclical(int(years_str[-2]), 10)\n",
    "    years = cyclical(int(years_str[-1]), 10)\n",
    "    months = cyclical(int(month_str), 12)\n",
    "    days = cyclical(int(day_str), 31)\n",
    "    # print((centuries, decades, years, months, days))\n",
    "    # print(decades,years)\n",
    "    return torch.cat((centuries, decades, years, months, days), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "def process_point(point_str, highest_x, highest_y):\n",
    "    if 'POINT' in point_str:\n",
    "        point_str = point_str.split('POINT(')[1].split('))')[0]\n",
    "    elif 'Point' in point_str:\n",
    "        point_str = point_str.split('Point(')[1].split('))')[0]\n",
    "    point_list = point_str.strip(')').strip('(').split()\n",
    "    point = tuple([float(coord) for coord in point_list])\n",
    "    point_x,point_y = point\n",
    "    highest_x = point_x if point_x > highest_x else highest_x\n",
    "    highest_y = point_y if point_y > highest_y else highest_y\n",
    "    return point, highest_x, highest_y\n",
    "    \n",
    "\n",
    "def get_num_data(poly_str, max_x, y_max):\n",
    "    if 'POLYGON' in poly_str:\n",
    "        poly_str = poly_str.split('POLYGON ((')[1].split('))')[0]\n",
    "    elif 'Polygon' in poly_str:\n",
    "        poly_str = poly_str.split('Polygon ((')[1].split('))')[0]\n",
    "    poly_combi_str_list = [poly for poly in poly_str.split(',')]# refactor this later. someone is talking rlly loud and I can't think\n",
    "    try:\n",
    "        poly_tupled = [(float(poly.split()[0]),float(poly.split()[1])) for poly in poly_combi_str_list]\n",
    "    except ValueError:\n",
    "        poly_tupled = [(float(poly.split()[0].strip(')').strip('(')),\n",
    "                     float(poly.split()[1].strip(')').strip('('))) \n",
    "                    for poly in poly_combi_str_list]\n",
    "    x_max, y_max = max([x for x,y in poly_tupled]), max([y for x, y in poly_tupled])\n",
    "    x_max =  x_max if x_max > max_x else max_x\n",
    "    y_max =  y_max if y_max > max_y else max_y\n",
    "    x_mean = sum([tup[0] for tup in poly_tupled])/len(poly_tupled)\n",
    "    y_mean = sum([tup[1] for tup in poly_tupled])/len(poly_tupled)\n",
    "    return poly_tupled, x_mean, y_mean, x_max, y_max\n",
    "\n",
    "\n",
    "global_mean_x = 0\n",
    "global_mean_y = 0\n",
    "\n",
    "print(point)\n",
    "max_x = 0\n",
    "max_y = 0\n",
    "\n",
    "points_tupled = []\n",
    "for i, point in enumerate(point_set):\n",
    "    point_tupled,max_x,max_y = process_point(point,max_x,max_y)\n",
    "    points_tupled.append(point_tupled)\n",
    "\n",
    "\n",
    "polys_tupled = []\n",
    "x_max, y_max = 0,0\n",
    "for i, poly in enumerate(poly_set):\n",
    "    # if i < 100:\n",
    "    poly_tupled, x_mean, y_mean, x_max, y_max = get_num_data(poly, x_max, y_max)\n",
    "    global_mean_x += 1\n",
    "    global_mean_y += 1\n",
    "    polys_tupled.append(poly_tupled)\n",
    "i += 1\n",
    "print(poly_tupled[0])\n",
    "global_mean_x, global_mean_y = global_mean_x/i, global_mean_y/i\n",
    "\n",
    "\n",
    "character_map = {char:i for i,char in enumerate(printable)}\n",
    "character_map['\\x7f'] = 101\n",
    "strings = []\n",
    "for s in string_set:\n",
    "    str_feature = tokenize_string(s, character_map)\n",
    "    strings.append(str_feature)\n",
    "\n",
    "imgs = []\n",
    "for img in image_set:\n",
    "    img_feature = encode_image(img)\n",
    "    imgs.append(img_feature)\n",
    "\n",
    "nums = []\n",
    "for n in num_set:\n",
    "    norm_fac = max(num_set)\n",
    "    num_feature = encode_num(n, norm_fac)\n",
    "    nums.append(num_feature)\n",
    "\n",
    "poly_features = []\n",
    "for i,poly in enumerate(polys_tupled):\n",
    "    poly_feature = encode_polygon(poly, global_mean_x, global_mean_y, x_max, y_max)\n",
    "    poly_features.append(poly_feature)\n",
    "    if i<10:\n",
    "        # print(poly)\n",
    "        # print(embedding)\n",
    "        pass\n",
    "\n",
    "point_features = []\n",
    "for point_tup in points_tupled:\n",
    "    # print(point)\n",
    "    point_feature = encode_point(point_tup, max_x, max_y)\n",
    "    point_features.append(point_feature)\n",
    "        # print(point)\n",
    "        # print(embedding)\n",
    "print(point)\n",
    "\n",
    "date_features = []\n",
    "for d in date_set:\n",
    "    date_feature = encode_date(d)\n",
    "    date_features.append(date_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665e545-55fd-4e43-b244-879232d93871",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b3e27-8047-46ca-8954-c4566f66aa2e",
   "metadata": {},
   "source": [
    "images.memorix.nlrcedownloadfullsize\n",
    "bag.basisregistraties.overheid.nlbagidgeometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "34660fba-188d-4dfd-902e-b9c2173915e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "def decode_base64_jpg(encoded_str,log_note='pass values to decode_base_64_jpg'): # - to +, _ to /\n",
    "    \"\"\"\n",
    "    encoded_str: url safe base 64 jpg string --> image bytes string\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        image_bytes = base64.urlsafe_b64decode(encoded_str)\n",
    "        return image_bytes\n",
    "    except Exception as e:\n",
    "        logging.error(f\"{e} error encoding image at {log_note}\")\n",
    "        return None\n",
    "\n",
    "def save_bytes_to_jpg(image_bytes, item_num=0,folder='Downloads/ml4g/image_data/',name='decoded'):\n",
    "    filename = f'{folder}{name}_{item_num}.jpg'\n",
    "    with open(filename, 'wb') as img_file:\n",
    "        img_file.write(image_bytes)\n",
    "\n",
    "\n",
    "image_bytes = decode_base64_jpg(image_data)\n",
    "save_bytes_to_jpg(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc46d2-bbd8-4c2d-b84e-5fcd03230185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebb130-d436-4b20-bf1b-6b25f81f1b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb95125-0c9c-40db-8614-bcfdeebb3081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "193278ef-f16f-4a1b-8845-0f103501bc9f",
   "metadata": {},
   "source": [
    " 'isalnum',\n",
    " 'isalpha',\n",
    " 'isascii',\n",
    " 'isdecimal',\n",
    " 'isdigit',\n",
    " 'isidentifier',\n",
    " 'islower',\n",
    " 'isnumeric',\n",
    " 'isprintable',\n",
    " 'isspace',\n",
    " 'istitle',\n",
    " 'isupper',"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
