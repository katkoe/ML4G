{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42273873-942b-48f5-a6d9-b19b525497ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from collections import deque\n",
    "from torch.nn.functional import relu, prelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29c1948-345b-4ebd-bc9c-2fecd4fffa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: collect all incoming edges for coalescence (search how they do it so it's consistent)\n",
    "#todo: after implementing message pass algorithm, move it to forward pass (if possible... and if it doesn't overcomplicate modularly changing out attention structures...)\n",
    "#todo: try graph step passing new node and computational dependency subtrees--> trim subtrees and extend undiscovered. intuition: like a net with a ball (at new node), \n",
    "# cut off at k-hop depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9005177-8653-4c14-9a67-f12cc9a68b89",
   "metadata": {},
   "source": [
    "# GraphSearch for single hop message passing\n",
    "### new approach: graph class with nodes with child and parent links (for step and computational dependency subtree creation)\n",
    "###               step() can be a random (for now uniform random) selection from children. \n",
    "#### todo: implement k-hop dependency subtree creation and think about computational efficiency... Don't want to have exponential search overhead with hops..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "115bb309-17b5-4ecf-844a-f0e9b89beaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea: could it be possible to completely decouple the procedurality of the network and just assume it converges to something useful? \n",
    "#... Just randomly (as a function of local in/out degree) sample a layer from the network each time and just keep walking... \n",
    "#... Maybe this still allows for multi-granularity analysis, just less organized. This idea relies on some notion of convergence I think. \n",
    "#todo: inverse relations are added to the predicate set...\n",
    "#todo: make training script\n",
    "#todo: can enhance expressiveness by making transformation & aggregation steps 3 layer mlp's each. (in the case of the r-gcn these are the embedding layers)\n",
    "# other option: can add mlp layers before and after the gnn, as pre-processing layers.\n",
    "# skip connections can be used to reduce oversmoothing I.e. k-hop 3 gets preprocessed and passed past k-hop 2 as well as into it (duplication) and just gets summed together with k-hop2 outputs\n",
    "# note that R-GCN uses normalized sum aggregation Also has edge dropout before batch norm\n",
    "# R-GCN uses full batch adam (rmsprop+momentum) for 400 epochs\n",
    "# R-GCN activation = relu, but relu-->relu-->softmax for entity classification makes sense ofcourse.\n",
    "# can kind of see embeddings as eigenvectors of the implications of the structure of the graph under random walk\n",
    "# check spectral node representation... its equal to the svd\n",
    "# graph laplacian  adj matrix (alternative repr for adj matrix)--> decomp\n",
    "# inverse relations and equality relations \n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import prelu, relu\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict, deque\n",
    "import random\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "EMBEDDING_SIZE = 5\n",
    "DIM_W = 5\n",
    "MAX_K_HOP = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# def message():\n",
    "\n",
    "#end to end... some choice for type(input) in inputs module dict(input)(input)\n",
    "\n",
    "class NodeClassifier(nn.Module):\n",
    "    def __init__(self, x_dim, num_classes):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "        mlp_layers = []\n",
    "        for _ in range(2):\n",
    "            mlp_layers.append(nn.Linear(x_dim, x_dim))\n",
    "            mlp_layers.append(nn.PReLU())\n",
    "            mlp_layers.append(nn.Dropout(p=0.2))\n",
    "            mlp_layers.append(nn.LayerNorm(x_dim))\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        self.linear = nn.Linear(x_dim, num_classes)\n",
    "        # self.softmax = nn.Softmax(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mlp = self.mlp(x)\n",
    "        return self.linear(mlp)\n",
    "        \n",
    "\n",
    "class R_GCNLayer(nn.Module):\n",
    "    #todo: handle size 0 batches\n",
    "    def __init__(self, x_dim ,y_dim, unique_labels, num_mlp_layers=1):\n",
    "        super(R_GCNLayer, self).__init__()\n",
    "        self.edge_label_weights = nn.ModuleDict({label: nn.Linear(x_dim, y_dim) for label in unique_labels})\n",
    "        self.y_dim = y_dim\n",
    "        self.x_dim = x_dim\n",
    "        self.unique_labels = list(unique_labels)\n",
    "        mlp_layers = []\n",
    "        # for _ in range(1):\n",
    "        #     mlp_layers.append(nn.Linear(y_dim, y_dim))\n",
    "        #     mlp_layers.append(nn.PReLU())\n",
    "        #     mlp_layers.append(nn.Dropout(p=0.2))\n",
    "        #     mlp_layers.append(nn.LayerNorm(y_dim))\n",
    "        self.lin = nn.Linear(x_dim, y_dim)\n",
    "        self.act = nn.ReLU()\n",
    "        self.do = nn.Dropout(p=0.2)\n",
    "        self.ln = nn.LayerNorm(y_dim)\n",
    "        # self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, layer_node_batch, agg_method=torch.sum):\n",
    "            device = next(self.parameters()).device\n",
    "            non_linear = []\n",
    "\n",
    "            for i, node in enumerate(layer_node_batch):\n",
    "                messages = node.collect_neighbours()\n",
    "                transformed_messages = defaultdict(list)\n",
    "\n",
    "                if messages:\n",
    "                    for message in messages: #< this is a bit slow probably... don't know how to change it yet because of the different edge weights.\n",
    "                        for parent_id, (embedding, edge_label, receiver_node_id) in message.items():\n",
    "                            transformed = self.edge_label_weights[edge_label](embedding)\n",
    "                            transformed_messages[i].append(transformed)\n",
    "\n",
    "                    aggregated = agg_method(torch.stack(transformed_messages[i])) + self.mlp(node.embedding)\n",
    "                    non_linear_i = self.prelu(aggregated)\n",
    "                else:\n",
    "                    transformed = torch.zeros(self.y_dim, dtype=torch.float32, device=device)\n",
    "                    aggregated = self.mlp(node.embedding)\n",
    "                    non_linear_i = self.prelu(aggregated)\n",
    "\n",
    "                non_linear.append(non_linear_i)\n",
    "            return torch.stack(non_linear)\n",
    "\n",
    "    def forward(self, layer_node_batch, agg_method=torch.sum):\n",
    "        #vectorized a bit further...\n",
    "        device = next(self.parameters()).device\n",
    "        outputs = []\n",
    "\n",
    "        for i, node in enumerate(layer_node_batch):\n",
    "            message_tensors, all_labels = node.collect_neighbour_tensors()\n",
    "            \n",
    "            if message_tensors:\n",
    "                aggregated_all = torch.zeros((1, self.x_dim),dtype = torch.float32).to(device)\n",
    "                for label in all_labels:\n",
    "                    message_tensors[label] = torch.stack(message_tensors[label])\n",
    "\n",
    "                    transformed = self.edge_label_weights[label](message_tensors[label])\n",
    "                    activated = self.act(transformed)\n",
    "                    \n",
    "                    aggregated = agg_method(activated, dim=0)\n",
    "                    aggregated = aggregated.unsqueeze(0)\n",
    "                    aggregated_all = torch.cat((aggregated_all,aggregated),dim=0)\n",
    "                                               \n",
    "                personal_message = self.lin(node.embedding)\n",
    "                personal_message_activated = self.act(personal_message)\n",
    "                aggregated_all = agg_method(aggregated_all,dim=0)\n",
    "\n",
    "                aggregated_all +=  personal_message\n",
    "                dropout = self.do(aggregated_all)\n",
    "                normalized = self.ln(dropout)\n",
    "\n",
    "            else:\n",
    "                transformed = torch.zeros(self.y_dim, dtype=torch.float32, device=device)\n",
    "                aggregated = self.act(self.lin(node.embedding))\n",
    "                dropout = self.do(aggregated)\n",
    "                normalized = self.ln(dropout)\n",
    "                \n",
    "\n",
    "            outputs.append(normalized)\n",
    "        return torch.stack(outputs)\n",
    "\n",
    "\n",
    "\n",
    "class R_GCN(nn.Module): #change to include GCN layers and assign them batches (split them up in forward and handle them sequentially including node update)\n",
    "    #it's a dependency bottleneck\n",
    "    def __init__(self, x_dim, y_dim, graph, max_k_hop):\n",
    "        super(R_GCN, self).__init__()\n",
    "        self.graph = graph\n",
    "        self.max_k_hop =max_k_hop\n",
    "        self.x_dim = x_dim\n",
    "        self.layers = nn.ModuleList([\n",
    "            R_GCNLayer(x_dim, y_dim, graph.unique_labels) \n",
    "            for _ in range(max_k_hop + 1)\n",
    "        ])\n",
    "        \n",
    "    \n",
    "    def forward(self, node_batch, agg_method=torch.sum): #maybe handle k_hops outside? have it be a single layer...\n",
    "        mini_batch = defaultdict(list)\n",
    "        target_node = node_batch[0][0]\n",
    "        \n",
    "        for node, k in node_batch:\n",
    "            layer = k\n",
    "            mini_batch[layer].append(node)\n",
    "            \n",
    "        updated_embeddings = {}\n",
    "        for layer in reversed(list(mini_batch.keys())):\n",
    "            batch = mini_batch[layer]\n",
    "            batch_size = len(batch)\n",
    "            # print(f'layer {layer} processing {batch_size} items...')\n",
    "            embeddings = self.layers[layer](batch)\n",
    "            for i, node in enumerate(batch):\n",
    "                try:\n",
    "                    updated_embeddings[node.id] = embeddings[i]\n",
    "                except:\n",
    "                    pass\n",
    "            for node in mini_batch[layer]:\n",
    "                node.embedding = updated_embeddings[node.id]\n",
    "        return target_node.embedding, torch.stack([updated_embeddings[node.id] for node,k in node_batch], dim=0)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id_):\n",
    "        self.id = id_\n",
    "        self.embedding = torch.rand(EMBEDDING_SIZE, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.features = {}\n",
    "        self.parents = {}\n",
    "        self.children = {}\n",
    "        self.out_edges = []\n",
    "\n",
    "\n",
    "    def collect_neighbours(self):\n",
    "        local_tree = []\n",
    "        for parent, labels in self.parents.items():\n",
    "            for label in labels:\n",
    "                local_tree.append({parent.id: (parent.embedding, label, self.id)})\n",
    "        return local_tree\n",
    "\n",
    "    def collect_neighbour_tensors(self):\n",
    "        embedding_dict = defaultdict(tuple)\n",
    "        unique_labels_seen = set()\n",
    "        for parent, labels in self.parents.items():\n",
    "            for label in labels:\n",
    "                embedding_dict[label] += (parent.embedding,)\n",
    "                unique_labels_seen.add(label)\n",
    "        return embedding_dict, list(unique_labels_seen)\n",
    "                \n",
    "                \n",
    "                \n",
    "    \n",
    "    def print_out_degree(self):\n",
    "        out_edges = [(label,target.id) for label,target in self.out_edges]\n",
    "        print(f\"Out edges: {out_edges}\") if out_edges else print(f'Node {self.id} has no children')\n",
    "\n",
    "    def adjust_embeddings(self, new_embedding):\n",
    "        self.embedding = new_embedding\n",
    "\n",
    "    def add_parent(self, parent_node, label):\n",
    "        if parent_node not in self.parents:\n",
    "            self.parents[parent_node] = []\n",
    "        self.parents[parent_node].append(label)\n",
    "\n",
    "    def add_child(self, child_node, label):\n",
    "        if child_node not in self.children:\n",
    "            self.children[child_node] = []\n",
    "        self.children[child_node].append(label)\n",
    "        self.add_out_edge(label, child_node)\n",
    "\n",
    "    def add_out_edge(self, label, target):\n",
    "        self.out_edges.append((label, target))\n",
    "\n",
    "    def step(self):\n",
    "        if not self.children:\n",
    "            return None\n",
    "        edge_label, target_node = random.choice(self.out_edges)\n",
    "        return (target_node, edge_label)\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "        self.label_weights = {}\n",
    "        self.unique_labels = set()\n",
    "        self.inverse_labels = True\n",
    "\n",
    "    def add_node(self, id_, label):\n",
    "        if id_ not in self.nodes:\n",
    "            self.nodes[id_] = Node(id_)\n",
    "            self.nodes[id_].label = label\n",
    "\n",
    "    def add_edge(self, from_id, to_id, label):\n",
    "        #todo: switch to tensors... requires some different logic.\n",
    "        if from_id not in self.nodes:\n",
    "            self.add_node(from_id)\n",
    "        if to_id not in self.nodes:\n",
    "            self.add_node(to_id)\n",
    "            \n",
    "        \n",
    "        from_node = self.nodes[from_id]\n",
    "        to_node = self.nodes[to_id]\n",
    "        from_node.add_child(to_node, label)\n",
    "        to_node.add_parent(from_node, label)\n",
    "        self.unique_labels.add(label)\n",
    "        if self.inverse_labels: #learnable inverse predicate relations from the R-GCN paper.\n",
    "            inverse_label = label + ':inv:'\n",
    "            from_node.add_child(to_node, inverse_label)\n",
    "            to_node.add_parent(from_node, inverse_label)\n",
    "            self.unique_labels.add(inverse_label)\n",
    "\n",
    "    def initialize_label_weights(self):\n",
    "        for label in list(self.unique_labels):\n",
    "            self.label_weights[label] = torch.rand(DIM_W,dtype=torch.float32, requires_grad=True, device=device)\n",
    "    \n",
    "    def get_parents(self, id_):\n",
    "        node = self.nodes.get(id_)\n",
    "        return {parent.id: labels for parent, labels in node.parents.items()}\n",
    "\n",
    "    def get_children(self, id_):\n",
    "        node = self.nodes.get(id_)\n",
    "        return {child.id: labels for child, labels in node.children.items()}\n",
    "\n",
    "# pipeline: bfs_dep_tree --> loop (embedding = forward(collect_neighbours(bfs_dep_tree.get.pop()))  )\n",
    "# where the first item in bfs_dep_tree list is the node and the second is the gcn layer to be used.\n",
    "# collect neighbours also collects the edges for edge weights...\n",
    "#todo: create inverse relations for all relations in the graph (for example by annotating them with '-' and using - weights for them. \n",
    "#set rdfs:a weights to identity matrix??\n",
    "\n",
    "#idea save a queue snapshot when depth k-1 switches to depth k to pass with step() to next node.... i don't know how to find the edges after that...\n",
    "def bfs_dep_tree(start_node, max_depth):\n",
    "    queue = deque([(start_node, 0)])\n",
    "    dep_tree = []\n",
    "    visited = set()\n",
    "    \n",
    "    \n",
    "    while queue:\n",
    "        current_node, depth = queue.popleft()\n",
    "        if depth > max_depth:\n",
    "            break\n",
    "        # if depth == max_depth-1:\n",
    "        #     save_visited = visited\n",
    "        visited.add(current_node)\n",
    "        dep_tree.append((current_node, max(1,depth)))\n",
    "        for parent in current_node.parents:\n",
    "            if parent not in visited:\n",
    "                queue.append((parent, depth + 1))\n",
    "    return dep_tree, start_node.label#, save_visited\n",
    "\n",
    "def bfs_dep_tree_computation_skip(start_tree, start_node, start_edge, max_depth): \n",
    "    #same as bfs_dep_tree, but skipping redundant computation.\n",
    "    #intuition: like taking the dependency tree of the last node which is connected \n",
    "    #           and trimming the leaves and adding it to the next node, allowing us to skip\n",
    "    #           computation for the edge we just came from.\n",
    "    skip_edge = start_edge\n",
    "    queue = deque([(start_node,0)])\n",
    "    visited = set()\n",
    "    dep_tree = []\n",
    "\n",
    "    while queue:\n",
    "        current_node, depth =  queue.popleft()\n",
    "        if depth > max_depth-1:\n",
    "            save_visited = visited\n",
    "        if depth > max_depth:\n",
    "            break\n",
    "        visited.add(current_node)\n",
    "        if current_node.id in skip_edge: #logic incomplete... now it skips some edges to the node it came from???? im not sure about this...\n",
    "            continue\n",
    "        dep_tree.append((current_node, max(1,depth)))\n",
    "        for parent in current_node.parents:\n",
    "            if parent not in visited:\n",
    "                queue.append((parent, depth + 1))\n",
    "    return dep_tree, save_visited\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61cc2c03-cf0d-427c-9104-66866d44b1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1974, 0.3270, 0.4556, 0.0978, 0.9606],\n",
       "        [0.7984, 0.7639, 0.9763, 0.3604, 0.0515]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(5)\n",
    "b = torch.rand(5)\n",
    "torch.stack((a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84b020c5-4c98-468a-8dd5-8b9d12a8a287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(NUM_CLASSES, dtype=torch.long, device=device)[random.choice(unique_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39da86-ddf0-49a5-99a1-01b0564a3bda",
   "metadata": {},
   "source": [
    "## Test some stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1d0ac13-767d-47ac-86b6-22955bfdec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=Graph()\n",
    "nodes=[]\n",
    "num_nodes = 100\n",
    "NUM_CLASSES = 15\n",
    "unique_classes = range(NUM_CLASSES)\n",
    "for n in range(0, num_nodes):\n",
    "    # graph.add_node(n, torch.eye(NUM_CLASSES, dtype=torch.torch.float32, device=device)[random.choice(unique_classes)])\n",
    "    graph.add_node(n, random.choice(unique_classes))\n",
    "    nodes.append(n)\n",
    "\n",
    "preds = [\"geometry:triangle\",\"rdfs:subClassOf\",\"FOAF:likes\",\"rdfs:subClassOf\",\"rdfs:domain\",\"FOAF:knows\",\"rdfs:isDefinedBy\"]\n",
    "for e in range(400):\n",
    "    obj = random.choice(nodes)\n",
    "    subj = random.choice([node for node in nodes if node != obj])\n",
    "    pred = random.choice(preds)\n",
    "    graph.add_edge(obj,subj,pred)\n",
    "graph.initialize_label_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb594bf-c58a-400e-893e-1a836146a1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20d5981e-6176-4ef2-9b9b-4e19e1c750ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A = graph.nodes[0]\n",
    "# node = A\n",
    "# k_hops = 3\n",
    "\n",
    "# dep_tree = bfs_dep_tree(node, k_hops)\n",
    "# # dep_tree[-1][0].parents\n",
    "# # set([dep[0].id for dep in dep_tree])\n",
    "# print(dep_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6290f1b1-84f7-43a7-a9ce-a8ac7c277877",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     skip_edge = (start_edge, last_node)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     batch, step_queue = bfs_dep_tree_computation_skip(start_tree, target_node, skip_edge, k_hops)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_node\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: embedding: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_node\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m---> 23\u001b[0m updated_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mr_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_node\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: embedding: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_node\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[90], line 147\u001b[0m, in \u001b[0;36mR_GCN.forward\u001b[0;34m(self, node_batch, agg_method)\u001b[0m\n\u001b[1;32m    144\u001b[0m mini_batch \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    145\u001b[0m target_node \u001b[38;5;241m=\u001b[39m node_batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node, k \u001b[38;5;129;01min\u001b[39;00m node_batch:\n\u001b[1;32m    148\u001b[0m     layer \u001b[38;5;241m=\u001b[39m k\n\u001b[1;32m    149\u001b[0m     mini_batch[layer]\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "graph.initialize_label_weights()\n",
    "target_node = graph.nodes[0]\n",
    "k_hops = 5\n",
    "r_gcn = R_GCN(x_dim=EMBEDDING_SIZE, y_dim=EMBEDDING_SIZE, graph=graph, max_k_hop=k_hops)\n",
    "WALK = 50\n",
    "node_list = [node for i, node in graph.nodes.items()]\n",
    "#I think node.step() can be replaced by a uniform random selection from the tree. This would also limit thingy... \n",
    "#  the computation skip on the dep tree. Just fix this later maybe. \n",
    "#Can also just construct the dataset and load it using a generator. \n",
    "#Dataset creation should be paralellizable with distributed or mpi if python has that.\n",
    "###check if dataset creation for GCN uses (informed)random walk or some random selection from list of nodes.\n",
    "###I think it's parralel full batch creation... \n",
    "#for i in range(WALK):\n",
    "while node_list:\n",
    "    target_node = node_list.pop()\n",
    "    r =  random.random() < 0.01\n",
    "    #if i == 0:\n",
    "    batch = bfs_dep_tree(target_node, k_hops)#,start_tree\n",
    "    # else:\n",
    "    #     skip_edge = (start_edge, last_node)\n",
    "    #     batch, step_queue = bfs_dep_tree_computation_skip(start_tree, target_node, skip_edge, k_hops)\n",
    "    print(f\"node: {target_node.id}: embedding: {target_node.embedding}\") if r else 5\n",
    "    updated_embedding = r_gcn(batch)\n",
    "    print(f\"node: {target_node.id}: embedding: {target_node.embedding}\") if r else 5\n",
    "    if r:\n",
    "        break\n",
    "    # try:\n",
    "    #     last_node = target_node\n",
    "    #     target_node, edge_label = target_node.step()\n",
    "    # except:\n",
    "    #     try:\n",
    "    #         last_node = target_node\n",
    "    #         target_node, edge_label = target_node.step()\n",
    "    #     except:\n",
    "    #         print(target_node.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7cf2c21-a2d0-433f-9bed-42bbb8b069d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/royal-cookings/Downloads'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml4g/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41f478-d291-4a34-a0a7-7af5c9c0b712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0/10: 17it [00:07,  1.75it/s]"
     ]
    }
   ],
   "source": [
    "folder_loc = \"./ml4g/dataset\" \n",
    "import os\n",
    "os.makedirs(folder_loc, exist_ok=True)\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "graph.initialize_label_weights()\n",
    "predicted_node = graph.nodes[0]\n",
    "k_hop = 5\n",
    "r_gcn = R_GCN(x_dim=EMBEDDING_SIZE, y_dim=EMBEDDING_SIZE, graph=graph, max_k_hop=k_hop)\n",
    "WALK = 50\n",
    "node_list = [node for i, node in graph.nodes.items()]\n",
    "NUM_CLASSES = 15\n",
    "\n",
    "def pkll(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        var = pickle.load(f)\n",
    "    return var\n",
    "\n",
    "def pkld(var,path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(var, f)\n",
    " \n",
    "\n",
    "def create_dataset(graph):\n",
    "    while node_list:\n",
    "        predicted_node = node_list.pop()\n",
    "        r =  random.randint(0,100)\n",
    "        batch = bfs_dep_tree(predicted_node, k_hop)\n",
    "        id_ = predicted_node.id\n",
    "        x, y = batch\n",
    "        pkld(x,f\"{folder_loc}/{id_}x.pkl\")\n",
    "        pkld(y,f\"{folder_loc}/{id_}y.pkl\")\n",
    "\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, folder_loc):\n",
    "        self.folder_loc = folder_loc\n",
    "        self.len = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.generate_micro_batches()\n",
    "    \n",
    "    def generate_micro_batches(self):\n",
    "        x_files = [os.path.join(self.folder_loc,file) for file in os.listdir(self.folder_loc) if file.endswith('x.pkl')]\n",
    "        y_files = [os.path.join(self.folder_loc,file) for file in os.listdir(self.folder_loc) if file.endswith('y.pkl')]\n",
    "        self.len = len(x_files)\n",
    "        for xpkl, ypkl in zip(x_files,y_files):\n",
    "            yield pkll(xpkl), pkll(ypkl)\n",
    "\n",
    "if not os.listdir(folder_loc):\n",
    "    create_dataset(graph)\n",
    "    print('creating')\n",
    "\n",
    "generator = Generator(folder_loc)\n",
    "r_gcn = R_GCN(x_dim=EMBEDDING_SIZE, y_dim=DIM_W, graph=graph, max_k_hop=k_hop)\n",
    "classifier = NodeClassifier(x_dim=DIM_W, num_classes=NUM_CLASSES)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "r_gcn.to(device)\n",
    "classifier.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params = list(r_gcn.parameters())\n",
    "params.extend(list(classifier.parameters()))\n",
    "optimizer = torch.optim.Adam(params,lr=0.01)\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "def save_gradient_hook(grad):\n",
    "    gradients.append(grad)\n",
    "    \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    r_gcn.train()\n",
    "    classifier.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    i = 0\n",
    "    # gradients = [] # can do some processing here to create alpha score from backpack library.\n",
    "    for batch, label in tqdm(generator, desc=f\"epoch {epoch}/{num_epochs}\"):\n",
    "        label = torch.tensor([label])\n",
    "        true_label = label.long().to(device)\n",
    "        predicted_embedding, _ = r_gcn(batch)\n",
    "        predicted_embedding = predicted_embedding.unsqueeze(0)\n",
    "        predicted_label = classifier(predicted_embedding)\n",
    "        \n",
    "        loss = criterion(predicted_label, true_label)\n",
    "\n",
    "        # for param in params:\n",
    "        #     param.register_hook(save_gradient_hook)\n",
    "        \n",
    "        if i % batch_size == 0:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        i += 1\n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = torch.max(predicted_label.data, 1)\n",
    "        total += 1\n",
    "        correct += 1 if predicted == true_label else 0\n",
    "    avg_loss = epoch_loss / generator.len\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"epoch: {epoch}\\navg loss: {avg_loss}accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a0e21b01-b4c4-4328-baf1-6c3ae950dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1026, 0.2904,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0757, 0.0000, 0.4580, 0.0000, 0.7416,\n",
    "        0.0000, 0.0000, 0.0000, 0.5146, 0.0000, 0.2533, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.5674, 0.2455, 0.0000, 0.1071, 0.0000, 0.5363, 0.8724, 0.3041,\n",
    "        0.4951, 0.0000, 0.0000, 0.2391, 0.1610, 0.5132, 0.0000, 0.0000, 0.4578])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dce82656-e827-47a5-8968-d4c2ca707fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 45])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.unsqueeze(0)\n",
    "b = a\n",
    "c = torch.cat((a,b),dim=0)\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "86a2338f-e2db-423f-bab1-dfb465746cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9352)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89da5c96-1161-4f54-bcc2-775d74588d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def generate_micro_batches(folder_loc):\n",
    "#     files = [os.path.join(folder_loc,file) for file in os.listdir(folder_loc) if file.endswith('.pkl')]\n",
    "#     for pkl in files:\n",
    "#         yield pkll(pkl)\n",
    "\n",
    "# generator = generate_micro_batches(folder_loc)\n",
    "next(generator)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70e6ba5e-ad64-40e3-b70d-a4dbeb991e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "one_hot(torch.tensor(14), num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cab8a247-bed8-4a9f-947a-9654c0d33033",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__init__(folder_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6439985-c221-44a2-97e1-f3043ef3243e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[os.path.join(folder_loc, file) for file in os.listdir(folder_loc) if file.endswith('.pkl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4b02f57-e6ad-4d86-a5a7-4e226b3db262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702c265e-18d6-4d61-8ccd-a21dff8a539a",
   "metadata": {},
   "source": [
    "## will make some parallel processing functions here once I understand the full training process..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c62421a-0e2a-40f6-a0fc-0cd8d455453c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2787165626.py, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 40\u001b[0;36m\u001b[0m\n\u001b[0;31m    workers = [Process(target=worker_num. args=)]\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "folder_loc = \"./ml4g/generator_batch\" \n",
    "from pickle import pickle\n",
    "from multiprocessing import Process, Queue\n",
    "import os\n",
    "\n",
    "def pkld(var,path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(var, f)\n",
    "\n",
    "def pkll(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        var = pickle.load(f)\n",
    "    return var\n",
    "\n",
    "def create_generator_folder(folder_loc): #consider modular full batch layer-wise processing if memory dep < some safety margin of ram/vram, etc\n",
    "    #else: parallel process micro batches if feasible\n",
    "    i = 0\n",
    "    while node_list:\n",
    "        target_node = node_list.pop()\n",
    "        #if i == 0:\n",
    "        batch, _ = bfs_dep_tree(target_node, k_hops)\n",
    "        pkld(batch, folder_loc+f\"/micro_batch_{i}.pkl\")\n",
    "        i += 1\n",
    "\n",
    "def generate_full_batch(folder_loc):\n",
    "    return [batch for batch in generate_micro_batches]\n",
    "\n",
    "\n",
    "def generate_micro_batches(folder_loc):\n",
    "    files = [file for file in os.listdir(folder_loc) if file.endswith('.pkl')]\n",
    "    for pkl in files:\n",
    "        yield pkll(pkl)\n",
    "\n",
    "def distribute_work(num_workers, micro_batches):\n",
    "    tasks = Queue()\n",
    "    output = Queue()\n",
    "    for task in micro_batches:\n",
    "        tasks.put(task)\n",
    "        forward_micro_batch(worker_num, task)\n",
    "    workers = [Process(target=worker_num. args=)]\n",
    "\n",
    "def forward_micro_batch(worker_num, micro_batch):\n",
    "    updated_embedding = await(r_gcn(micro_batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de034418-e741-4f35-b776-a4c3c29aaa0f",
   "metadata": {},
   "source": [
    "## RDFS Process to Graph() object below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ec560-5ad6-47cd-850e-d3c4517fac33",
   "metadata": {},
   "outputs": [],
   "source": [
    ":)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186637d3-124d-4793-ba9c-eee99f87bbf4",
   "metadata": {},
   "source": [
    "### cashew: try graphgym package :)\n",
    "# Proposed GNN architecture:\n",
    "## Transformation block >>>\n",
    "### * linear\n",
    "### * batch norm * <  my intuition is that this could replace mean() operation, just use vectorized sum() to reduce computational complexity.\n",
    "### * dropout * < On linear layer in the message function\n",
    "### * activation * < parametric relu = max(x,0) + alpha * min(x,0) ... alpha is trainable.\n",
    "### * attention * < I'm not sure if relational weights as in RGCN fall into this category. If they are complementary in any way.\n",
    "## <<< End transformation block\n",
    "### * aggregation by some problem dependant function i.e. mean(), min/max/avg..._pooling(), lstm(cat(edge_embeddings)) ...\n",
    "#### aggregation note: inverted degree matrix * adjacency matrix = avg(adjacency matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c958c6-c608-46dc-9be5-7f95a50582cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be97b1f-8733-4f96-860c-8f66a81e8b90",
   "metadata": {},
   "source": [
    "# classical GCN:\n",
    "\n",
    "## important design choice here... use batch norm after each layer? Normalize explicitly?\n",
    "## messages = layer weight * normalized messages from prev layers\n",
    "## aggregation = sum(messages) --> relu\n",
    "\n",
    "### todo: add weighted average method. I.e. learnable row vector of size feature dim (must vectorize torch.mean explicitly for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0813b833-f070-43cf-9d95-0233534591f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "205882e8-df3d-407f-9a5d-69668314c372",
   "metadata": {},
   "source": [
    "# GraphSAGE\n",
    "## aggregate incoming messages (can be mean(messages, dim=0), can be a max pooling on mlp(message), can be LSTM(shuffle(messages) as mini-batch), can be sum without average (maybe this leads to batch norm later?)\n",
    "## concat current node message --> relu --> send\n",
    "\n",
    "## Uses L2 Norm as root squared error of embeddings at every layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a23ab-9bd8-45a4-bfb1-5615bd73e494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7de03bc5-9d73-44ba-ad3c-dfde101d4eb7",
   "metadata": {},
   "source": [
    "# GAT\n",
    "\n",
    "# Architectural notes:\n",
    "\n",
    "## GCN, but vector weighting matrix is learned (which nodes to attend to and ./ unsure./ which parts of the embedding vectors/features to attend to \\.\\.\n",
    "\n",
    "### how can we handle permutation invariance?\n",
    "\n",
    "### seems that attention weights are graph conditional on search algorithm dependant\n",
    "\n",
    "### ^ wrong. It's a function of (and on) embeddings of different node embeddings at the previous step.\n",
    "\n",
    "### softmax ()\n",
    "\n",
    "### parameter matrix a can be a parameter matrix on a learned single layer mlp that processes the concatenated input vectors.\n",
    "\n",
    "### parameter matrix a is learned together with weight matrix w.\n",
    "\n",
    "### multi-head attention, multiple relu(a) matrices.\n",
    "\n",
    "### each a is initialized randomly, then aggregated to produce a single output\n",
    "\n",
    "### can be parallellized worker per message.\n",
    "\n",
    "### sparse matrix... fixed number of parameters.\n",
    "\n",
    "# Implications/discussion\n",
    "\n",
    "### asymmetric importance weighting\n",
    "\n",
    "### weights are still independant of graph size, even though more complex analysis of the graph can be performed.\n",
    "\n",
    "### graph attention mechanism scales linearly in graph size due to locality\n",
    "\n",
    "### cool visualization of attention mechanism (implicit clustering) cora citation paper\n",
    "\n",
    "### improved performance over GCN in some cases.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94542b15-3eab-42a7-bbe3-7410cf035385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e92fe-b919-46fa-8eec-f834fc086c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d035a923-461f-4dc5-8453-d3faa6f66f60",
   "metadata": {},
   "source": [
    "# Test stuff and transform into main() below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b355090-c13a-4404-823a-60f59a9b1a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d5b48-9b43-4393-83d7-aa237e6322db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
